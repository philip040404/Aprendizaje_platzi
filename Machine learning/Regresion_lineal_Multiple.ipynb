{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./Material/Datasets/50_startups.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:, 3] = labelencoder_X.fit_transform(X[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\delgaf18\\OneDrive - Medtronic PLC\\Trabajo\\Proyectos de automatizacion\\Aprendizaje y codigos base\\Aprendizaje_platzi\\Machine learning\\Regresion_lineal_Multiple.ipynb Cell 5\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/delgaf18/OneDrive%20-%20Medtronic%20PLC/Trabajo/Proyectos%20de%20automatizacion/Aprendizaje%20y%20codigos%20base/Aprendizaje_platzi/Machine%20learning/Regresion_lineal_Multiple.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ct \u001b[39m=\u001b[39m ColumnTransformer(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/delgaf18/OneDrive%20-%20Medtronic%20PLC/Trabajo/Proyectos%20de%20automatizacion/Aprendizaje%20y%20codigos%20base/Aprendizaje_platzi/Machine%20learning/Regresion_lineal_Multiple.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     [(\u001b[39m'\u001b[39m\u001b[39mcountry\u001b[39m\u001b[39m'\u001b[39m, OneHotEncoder(categories\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m), [\u001b[39m3\u001b[39m])],    \u001b[39m# The column numbers to be transformed (here is [0] but can be [0, 1, 3])\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/delgaf18/OneDrive%20-%20Medtronic%20PLC/Trabajo/Proyectos%20de%20automatizacion/Aprendizaje%20y%20codigos%20base/Aprendizaje_platzi/Machine%20learning/Regresion_lineal_Multiple.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     remainder\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m                         \u001b[39m# Leave the rest of the columns untouched\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/delgaf18/OneDrive%20-%20Medtronic%20PLC/Trabajo/Proyectos%20de%20automatizacion/Aprendizaje%20y%20codigos%20base/Aprendizaje_platzi/Machine%20learning/Regresion_lineal_Multiple.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m )\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/delgaf18/OneDrive%20-%20Medtronic%20PLC/Trabajo/Proyectos%20de%20automatizacion/Aprendizaje%20y%20codigos%20base/Aprendizaje_platzi/Machine%20learning/Regresion_lineal_Multiple.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m x \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(ct\u001b[39m.\u001b[39mfit_transform(X), dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39;49mfloat)\n",
      "File \u001b[1;32mc:\\Users\\delgaf18\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\__init__.py:338\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    333\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    334\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIn the future `np.\u001b[39m\u001b[39m{\u001b[39;00mattr\u001b[39m}\u001b[39;00m\u001b[39m` will be defined as the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    335\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcorresponding NumPy scalar.\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m    337\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 338\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    340\u001b[0m \u001b[39mif\u001b[39;00m attr \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtesting\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    341\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtesting\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float'.\n`np.float` was a deprecated alias for the builtin `float`. To avoid this error in existing code, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "ct = ColumnTransformer(\n",
    "    [('country', OneHotEncoder(categories='auto'), [3])],    # The column numbers to be transformed (here is [0] but can be [0, 1, 3])\n",
    "    remainder='passthrough'                         # Leave the rest of the columns untouched\n",
    ")\n",
    "x = np.array(ct.fit_transform(X), dtype=np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehotencoder = OneHotEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "\n",
    "# Evitar la trampa de las variables ficticias\n",
    "X = X[:, 1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el data set en conjunto de entrenamiento y conjunto de testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ajustar el modelo de Regresión lineal múltiple con el conjunto de entrenamiento\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regression = LinearRegression()\n",
    "regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción de los resultados en el conjunto de testing\n",
    "y_pred = regression.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112777.51325257, 100304.42734969, 111216.61305713, 108582.26375353,\n",
       "       111630.83539076, 119466.51899435, 119493.82195131, 119462.93037442,\n",
       "       110836.53837737, 111630.83539076])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import *\n",
    "import numpy as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir el modelo óptimo de RLM utilizando la Eliminación hacia atrás\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((50,1)).astype(int), values = X, axis = 1)\n",
    "SL = 0.05\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 21 Nov 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0665</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:29:12</td>     <th>  Log-Likelihood:    </th> <td> -594.98</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1202.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    44</td>      <th>  BIC:               </th> <td>   1213.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.178e+05</td> <td> 5659.867</td> <td>   20.808</td> <td> 0.000</td> <td> 1.06e+05</td> <td> 1.29e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-8.209e+04</td> <td> 3.84e+04</td> <td>   -2.139</td> <td> 0.038</td> <td>-1.59e+05</td> <td>-4730.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-5.284e+04</td> <td> 3.84e+04</td> <td>   -1.377</td> <td> 0.176</td> <td> -1.3e+05</td> <td> 2.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-6.828e+04</td> <td> 3.84e+04</td> <td>   -1.779</td> <td> 0.082</td> <td>-1.46e+05</td> <td> 9086.971</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-4.801e+04</td> <td> 3.84e+04</td> <td>   -1.251</td> <td> 0.218</td> <td>-1.25e+05</td> <td> 2.94e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>-3.654e+04</td> <td> 3.84e+04</td> <td>   -0.952</td> <td> 0.346</td> <td>-1.14e+05</td> <td> 4.08e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.590</td> <th>  Durbin-Watson:     </th> <td>   0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.452</td> <th>  Jarque-Bera (JB):  </th> <td>   0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.059</td> <th>  Prob(JB):          </th> <td>   0.672</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.606</td> <th>  Cond. No.          </th> <td>    7.47</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        y         & \\textbf{  R-squared:         } &     0.203   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.113   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     2.244   \\\\\n",
       "\\textbf{Date:}             & Tue, 21 Nov 2023 & \\textbf{  Prob (F-statistic):} &   0.0665    \\\\\n",
       "\\textbf{Time:}             &     15:29:12     & \\textbf{  Log-Likelihood:    } &   -594.98   \\\\\n",
       "\\textbf{No. Observations:} &          50      & \\textbf{  AIC:               } &     1202.   \\\\\n",
       "\\textbf{Df Residuals:}     &          44      & \\textbf{  BIC:               } &     1213.   \\\\\n",
       "\\textbf{Df Model:}         &           5      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const} &    1.178e+05  &     5659.867     &    20.808  &         0.000        &     1.06e+05    &     1.29e+05     \\\\\n",
       "\\textbf{x1}    &   -8.209e+04  &     3.84e+04     &    -2.139  &         0.038        &    -1.59e+05    &    -4730.369     \\\\\n",
       "\\textbf{x2}    &   -5.284e+04  &     3.84e+04     &    -1.377  &         0.176        &     -1.3e+05    &     2.45e+04     \\\\\n",
       "\\textbf{x3}    &   -6.828e+04  &     3.84e+04     &    -1.779  &         0.082        &    -1.46e+05    &     9086.971     \\\\\n",
       "\\textbf{x4}    &   -4.801e+04  &     3.84e+04     &    -1.251  &         0.218        &    -1.25e+05    &     2.94e+04     \\\\\n",
       "\\textbf{x5}    &   -3.654e+04  &     3.84e+04     &    -0.952  &         0.346        &    -1.14e+05    &     4.08e+04     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  1.590 & \\textbf{  Durbin-Watson:     } &    0.512  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.452 & \\textbf{  Jarque-Bera (JB):  } &    0.795  \\\\\n",
       "\\textbf{Skew:}          & -0.059 & \\textbf{  Prob(JB):          } &    0.672  \\\\\n",
       "\\textbf{Kurtosis:}      &  3.606 & \\textbf{  Cond. No.          } &     7.47  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.203\n",
       "Model:                            OLS   Adj. R-squared:                  0.113\n",
       "Method:                 Least Squares   F-statistic:                     2.244\n",
       "Date:                Tue, 21 Nov 2023   Prob (F-statistic):             0.0665\n",
       "Time:                        15:29:12   Log-Likelihood:                -594.98\n",
       "No. Observations:                  50   AIC:                             1202.\n",
       "Df Residuals:                      44   BIC:                             1213.\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.178e+05   5659.867     20.808      0.000    1.06e+05    1.29e+05\n",
       "x1         -8.209e+04   3.84e+04     -2.139      0.038   -1.59e+05   -4730.369\n",
       "x2         -5.284e+04   3.84e+04     -1.377      0.176    -1.3e+05    2.45e+04\n",
       "x3         -6.828e+04   3.84e+04     -1.779      0.082   -1.46e+05    9086.971\n",
       "x4         -4.801e+04   3.84e+04     -1.251      0.218   -1.25e+05    2.94e+04\n",
       "x5         -3.654e+04   3.84e+04     -0.952      0.346   -1.14e+05    4.08e+04\n",
       "==============================================================================\n",
       "Omnibus:                        1.590   Durbin-Watson:                   0.512\n",
       "Prob(Omnibus):                  0.452   Jarque-Bera (JB):                0.795\n",
       "Skew:                          -0.059   Prob(JB):                        0.672\n",
       "Kurtosis:                       3.606   Cond. No.                         7.47\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "X_opt = X[:,[0,1,2,3,4,5]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 09 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0496</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:36:46</td>     <th>  Log-Likelihood:    </th> <td> -595.48</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1201.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    45</td>      <th>  BIC:               </th> <td>   1211.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  1.17e+05</td> <td> 5592.160</td> <td>   20.917</td> <td> 0.000</td> <td> 1.06e+05</td> <td> 1.28e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -8.13e+04</td> <td> 3.83e+04</td> <td>   -2.121</td> <td> 0.039</td> <td>-1.59e+05</td> <td>-4083.603</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-5.205e+04</td> <td> 3.83e+04</td> <td>   -1.358</td> <td> 0.181</td> <td>-1.29e+05</td> <td> 2.52e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-6.748e+04</td> <td> 3.83e+04</td> <td>   -1.760</td> <td> 0.085</td> <td>-1.45e+05</td> <td> 9733.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>-4.721e+04</td> <td> 3.83e+04</td> <td>   -1.232</td> <td> 0.225</td> <td>-1.24e+05</td> <td>    3e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 1.208</td> <th>  Durbin-Watson:     </th> <td>   0.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.547</td> <th>  Jarque-Bera (JB):  </th> <td>   0.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.012</td> <th>  Prob(JB):          </th> <td>   0.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.480</td> <th>  Cond. No.          </th> <td>    7.38</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.187\n",
       "Model:                            OLS   Adj. R-squared:                  0.115\n",
       "Method:                 Least Squares   F-statistic:                     2.584\n",
       "Date:                Thu, 09 Mar 2023   Prob (F-statistic):             0.0496\n",
       "Time:                        08:36:46   Log-Likelihood:                -595.48\n",
       "No. Observations:                  50   AIC:                             1201.\n",
       "Df Residuals:                      45   BIC:                             1211.\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        1.17e+05   5592.160     20.917      0.000    1.06e+05    1.28e+05\n",
       "x1          -8.13e+04   3.83e+04     -2.121      0.039   -1.59e+05   -4083.603\n",
       "x2         -5.205e+04   3.83e+04     -1.358      0.181   -1.29e+05    2.52e+04\n",
       "x3         -6.748e+04   3.83e+04     -1.760      0.085   -1.45e+05    9733.737\n",
       "x4         -4.721e+04   3.83e+04     -1.232      0.225   -1.24e+05       3e+04\n",
       "==============================================================================\n",
       "Omnibus:                        1.208   Durbin-Watson:                   0.460\n",
       "Prob(Omnibus):                  0.547   Jarque-Bera (JB):                0.481\n",
       "Skew:                          -0.012   Prob(JB):                        0.786\n",
       "Kurtosis:                       3.480   Cond. No.                         7.38\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,1,2,3,4]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.908</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 09 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0445</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:36:46</td>     <th>  Log-Likelihood:    </th> <td> -596.31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1201.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    46</td>      <th>  BIC:               </th> <td>   1208.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     3</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>  1.16e+05</td> <td> 5563.332</td> <td>   20.845</td> <td> 0.000</td> <td> 1.05e+05</td> <td> 1.27e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -8.03e+04</td> <td> 3.85e+04</td> <td>   -2.083</td> <td> 0.043</td> <td>-1.58e+05</td> <td>-2710.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-5.104e+04</td> <td> 3.85e+04</td> <td>   -1.324</td> <td> 0.192</td> <td>-1.29e+05</td> <td> 2.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>-6.648e+04</td> <td> 3.85e+04</td> <td>   -1.725</td> <td> 0.091</td> <td>-1.44e+05</td> <td> 1.11e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.787</td> <th>  Durbin-Watson:     </th> <td>   0.365</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.675</td> <th>  Jarque-Bera (JB):  </th> <td>   0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.028</td> <th>  Prob(JB):          </th> <td>   0.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.310</td> <th>  Cond. No.          </th> <td>    7.30</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.159\n",
       "Model:                            OLS   Adj. R-squared:                  0.105\n",
       "Method:                 Least Squares   F-statistic:                     2.908\n",
       "Date:                Thu, 09 Mar 2023   Prob (F-statistic):             0.0445\n",
       "Time:                        08:36:46   Log-Likelihood:                -596.31\n",
       "No. Observations:                  50   AIC:                             1201.\n",
       "Df Residuals:                      46   BIC:                             1208.\n",
       "Df Model:                           3                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        1.16e+05   5563.332     20.845      0.000    1.05e+05    1.27e+05\n",
       "x1          -8.03e+04   3.85e+04     -2.083      0.043   -1.58e+05   -2710.722\n",
       "x2         -5.104e+04   3.85e+04     -1.324      0.192   -1.29e+05    2.65e+04\n",
       "x3         -6.648e+04   3.85e+04     -1.725      0.091   -1.44e+05    1.11e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.787   Durbin-Watson:                   0.365\n",
       "Prob(Omnibus):                  0.675   Jarque-Bera (JB):                0.207\n",
       "Skew:                           0.028   Prob(JB):                        0.902\n",
       "Kurtosis:                       3.310   Cond. No.                         7.30\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,1,2,3]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 09 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td>0.0407</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:36:46</td>     <th>  Log-Likelihood:    </th> <td> -597.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1200.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    47</td>      <th>  BIC:               </th> <td>   1206.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.149e+05</td> <td> 5549.041</td> <td>   20.707</td> <td> 0.000</td> <td> 1.04e+05</td> <td> 1.26e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>-7.923e+04</td> <td> 3.88e+04</td> <td>   -2.040</td> <td> 0.047</td> <td>-1.57e+05</td> <td>-1089.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>-6.541e+04</td> <td> 3.88e+04</td> <td>   -1.684</td> <td> 0.099</td> <td>-1.44e+05</td> <td> 1.27e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.458</td> <th>  Durbin-Watson:     </th> <td>   0.343</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.796</td> <th>  Jarque-Bera (JB):  </th> <td>   0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.061</td> <th>  Prob(JB):          </th> <td>   0.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.144</td> <th>  Cond. No.          </th> <td>    7.22</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.127\n",
       "Model:                            OLS   Adj. R-squared:                  0.090\n",
       "Method:                 Least Squares   F-statistic:                     3.430\n",
       "Date:                Thu, 09 Mar 2023   Prob (F-statistic):             0.0407\n",
       "Time:                        08:36:46   Log-Likelihood:                -597.25\n",
       "No. Observations:                  50   AIC:                             1200.\n",
       "Df Residuals:                      47   BIC:                             1206.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.149e+05   5549.041     20.707      0.000    1.04e+05    1.26e+05\n",
       "x1         -7.923e+04   3.88e+04     -2.040      0.047   -1.57e+05   -1089.548\n",
       "x2         -6.541e+04   3.88e+04     -1.684      0.099   -1.44e+05    1.27e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.458   Durbin-Watson:                   0.343\n",
       "Prob(Omnibus):                  0.796   Jarque-Bera (JB):                0.074\n",
       "Skew:                           0.061   Prob(JB):                        0.964\n",
       "Kurtosis:                       3.144   Cond. No.                         7.22\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:,[0,1,3]]\n",
    "regressor_OLS = sm.OLS(endog=y, exog=X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.030</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   2.532</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 09 Mar 2023</td> <th>  Prob (F-statistic):</th>  <td> 0.118</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>08:36:46</td>     <th>  Log-Likelihood:    </th> <td> -599.37</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    50</td>      <th>  AIC:               </th> <td>   1203.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    48</td>      <th>  BIC:               </th> <td>   1207.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> 1.133e+05</td> <td> 5670.069</td> <td>   19.980</td> <td> 0.000</td> <td> 1.02e+05</td> <td> 1.25e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td> -6.38e+04</td> <td> 4.01e+04</td> <td>   -1.591</td> <td> 0.118</td> <td>-1.44e+05</td> <td> 1.68e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.164</td> <th>  Durbin-Watson:     </th> <td>   0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.921</td> <th>  Jarque-Bera (JB):  </th> <td>   0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.009</td> <th>  Prob(JB):          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.989</td> <th>  Cond. No.          </th> <td>    7.15</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.050\n",
       "Model:                            OLS   Adj. R-squared:                  0.030\n",
       "Method:                 Least Squares   F-statistic:                     2.532\n",
       "Date:                Thu, 09 Mar 2023   Prob (F-statistic):              0.118\n",
       "Time:                        08:36:46   Log-Likelihood:                -599.37\n",
       "No. Observations:                  50   AIC:                             1203.\n",
       "Df Residuals:                      48   BIC:                             1207.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       1.133e+05   5670.069     19.980      0.000    1.02e+05    1.25e+05\n",
       "x1          -6.38e+04   4.01e+04     -1.591      0.118   -1.44e+05    1.68e+04\n",
       "==============================================================================\n",
       "Omnibus:                        0.164   Durbin-Watson:                   0.114\n",
       "Prob(Omnibus):                  0.921   Jarque-Bera (JB):                0.001\n",
       "Skew:                           0.009   Prob(JB):                         1.00\n",
       "Kurtosis:                       2.989   Cond. No.                         7.15\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_opt = X[:, [0, 3]]\n",
    "regression_OLS = sm.OLS(endog = y, exog = X_opt.tolist()).fit()\n",
    "regression_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regression.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
